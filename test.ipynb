{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anonymizer.detection import Detector, get_weights_path\n",
    "from anonymizer.obfuscation import Obfuscator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './weights'\n",
    "kernel_size, sigma, box_kernel_size = 21,2,9\n",
    "obfuscator = Obfuscator(kernel_size=int(kernel_size), sigma=float(sigma), box_kernel_size=int(box_kernel_size))\n",
    "detectors = {\n",
    "    'face': Detector(kind='face', weights_path=get_weights_path(weights_path, kind='face')),\n",
    "    'plate': Detector(kind='plate', weights_path=get_weights_path(weights_path, kind='plate'))\n",
    "}\n",
    "detection_thresholds = {\n",
    "    'face': 0.3,\n",
    "    'plate': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(requests.get(\"https://raw.githubusercontent.com/understand-ai/anonymizer/master/images/coco01.jpg\", stream=True).raw).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_points(size, split_size, overlap=0, region_of_interest=None):\n",
    "    offset = 0\n",
    "\n",
    "    if region_of_interest:\n",
    "        size = region_of_interest[1] - region_of_interest[0]\n",
    "        offset = region_of_interest[0]\n",
    "    \n",
    "    stride = int(split_size * (1-overlap))\n",
    "    \n",
    "    points = []\n",
    "    counter = 0\n",
    "    \n",
    "    while True:\n",
    "        start_point = stride * counter\n",
    "        \n",
    "        if start_point + split_size >= size: # last box, will potentially exceed size\n",
    "            points.append((start_point+offset, size+offset))\n",
    "            break\n",
    "        \n",
    "        points.append((start_point+offset, start_point+split_size+offset))\n",
    "        counter += 1\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_width = 2000\n",
    "split_height = 2500\n",
    "overlap = 0.1 # 10% overlap for both x and y\n",
    "\n",
    "# for equirrectangular panoramas, we can ignore the upper and lower thirds\n",
    "if math.floor(image.width / image.height) == 2:\n",
    "    roi_start = math.floor(image.height * 0.4)\n",
    "    roi_stop = math.floor(image.height * 0.75)\n",
    "    region_of_interest = [roi_start, roi_stop]\n",
    "else:\n",
    "    region_of_interest = None\n",
    "\n",
    "X_points = start_points(image.width, split_width, overlap=overlap)\n",
    "Y_points = start_points(image.height, split_height, overlap=overlap, region_of_interest=region_of_interest)\n",
    "\n",
    "X_points, Y_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "for x_start, x_stop in X_points:\n",
    "    for y_start, y_stop in Y_points:\n",
    "        coords.append((x_start, x_stop, y_start, y_stop))\n",
    "\n",
    "print(f'Total of {len(coords)} splits')\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = []\n",
    "\n",
    "from anonymizer.utils import Box\n",
    "\n",
    "for x_start, x_stop, y_start, y_stop in coords:\n",
    "    tile = image.crop((x_start, y_start, x_stop, y_stop))\n",
    "    np_tile = np.array(tile)\n",
    "\n",
    "    for kind, detector in detectors.items():\n",
    "        boxes = detector.detect(np_tile, detection_threshold=detection_thresholds[kind])\n",
    "\n",
    "        for detection in boxes:\n",
    "            detections.append(Box(\n",
    "                detection.x_min + x_start,\n",
    "                detection.y_min + y_start,\n",
    "                detection.x_max + x_start,\n",
    "                detection.y_max + y_start,\n",
    "                detection.score,\n",
    "                detection.kind\n",
    "            ))\n",
    "\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = np.array(image)\n",
    "obfuscated_np_image = obfuscator.obfuscate(np_image, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated_image = Image.fromarray((obfuscated_np_image).astype(np.uint8), mode='RGB')\n",
    "obfuscated_image.save(f\"/Users/george/Sites/anonymizer/images-anonymized/result.jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2618300d29866c3c7331de57dac3b39f69158fad66853fef87459b28a97e265f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
